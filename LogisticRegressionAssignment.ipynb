{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is a classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification problem is when the output variable is a category, such as ‚Äúred‚Äù or ‚Äúblue‚Äù or ‚Äúdisease‚Äù and ‚Äúno disease‚Äù. A classification model attempts to draw some conclusion from observed values. Given one or more inputs a classification model will try to predict the value of one or more outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tWhat is Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is one such regression algorithm which can be used for performing classification problems. It calculates the probability that a given value belongs to a specific class. If the probability is more than 50%, it assigns the value in that particular class else if the probability is less than 50%, the value is assigned to the other class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tWhy is the Sigmoid function used for Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The sigmoid function‚Äôs range is bounded between 0 and 1. Thus it‚Äôs useful in calculating the probability for the Logistic function.\n",
    "2) It‚Äôs derivative is easy to calculate than other functions which is useful during gradient descent calculation.\n",
    "3) It is a simple way of introducing non-linearity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWhat is the cost function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number. Depending on the problem Cost Function can be formed in many different ways. The purpose of Cost Function is to be either:\n",
    "\n",
    "Minimized - then returned value is usually called cost, loss or error. The goal is to find the values of model parameters for which Cost Function return as small number as possible.\n",
    "\n",
    "Maximized - then the value it yields is named a reward. The goal is to find values of model parameters for which returned number is as large as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWhat is multiple Logistic Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " multiple logistic regression analysis applies when there is a single dichotomous outcome and more than one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWhat is multilabel Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel classification assigns to each sample a set of target labels. This can be thought as predicting properties of a data-point that are not mutually exclusive, such as topics that are relevant for a document. A text might be about any of religion, politics, finance or education at the same time or none of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tHow does the Logistic Regression Algorithm learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression uses batch Gradient Descent for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tExplain the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known\n",
    "The table will have prediction yes/no or 1/0 and column will have Actual values Yes/No or 0/1. The first cell in the row will be a True positive, second cell will be False negative, the first cell in the second row will be False positive and the second cell in the second row will be True negative\n",
    "\n",
    "True Positives (TP) - These are the correctly predicted positive values which means that the value of actual class is yes and the value of predicted class is also yes. \n",
    "\n",
    "True Negatives (TN) - These are the correctly predicted negative values which means that the value of actual class is no and value of predicted class is also no. \n",
    "\n",
    "False positives and false negatives, these values occur when your actual class contradicts with the predicted class.\n",
    "\n",
    "False Positives (FP) ‚Äì When actual class is no and predicted class is yes. \n",
    "\n",
    "False Negatives (FN) ‚Äì When actual class is yes but predicted class in no. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tWhat is Accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy=(ùëáùëÉ+ùëáùëÅ)/(ùëáùëÉ+ùëáùëÅ+ùêπùëÉ+ùêπùëÅ), \n",
    "Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tWhy there is a need for other metrics if ‚Äòaccuracy‚Äô is already present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy just check if the model has identified true positives and true negatives. It does not check if the model have done Flase negative and False positive. This means that it might have classified correct data to the corrresponding label but also classified other data to be positive. so we use other measures such as recall and  Precision in combination woth accuracy to check the performance of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.\tWhat are Recall and Precision? How do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations.  High precision relates to the low false positive rate. We have got 0.788 precision which is pretty good.\n",
    "\n",
    "Precision = TP/TP+FP\n",
    "\n",
    "Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes.  We have got recall of 0.631 which is good for this model as it‚Äôs above 0.5.\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "The difference is that if we take the case of a disease check, precision is the checking that out of all patients who are classified as having a disease how many do have disease on the other havd recall is checking out of all the patients who had disease how many did we find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.\tHow does the tradeoff between recall and precision work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we increase the recall precision will reduce and vice versa. So we need to find an optimal level at which recall and precision should be for the model. This decision is made with the demand of the model. Some model need more precision than recall and sometime more recall than precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.\tExplain the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score is the weighted average of Precision and Recall. F1 score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it‚Äôs better to look at F1 score. F1 is used when both precision and recall is important for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.\tWhat is specificity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity (also called the true negative rate) measures the proportion of negatives which are correctly identified as such (e.g., the percentage of healthy people who are correctly identified as not having the condition), and is complementary to the false positive rate. Specificity=true negatives/(true negative + false positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.\tExplain the significance of ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Area Under the ROC curve (AUC) is an aggregated metric that evaluates how well a logistic regression model classifies positive and negative outcomes at all possible cutoffs. It can range from 0.5 to 1, and the larger it is the better.The ROC curve does this by plotting sensitivity, the probability of predicting a real positive will be a positive, against 1-specificity, the probability of predicting a real negative will be a positive. ROC is used to find the optimal threshold where we can divide yes/no or 1/0 as logistic regression does not give exactly 0 or 1 as a result it gives any value between 0 and 1 from that we need to divied based on the requirement of the model , like above 0.5 should be 1 and  below or equal to 0.5 should be 0.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.\tWhat is AUC, and when is it used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC stands for Area under the curve. AUC gives the rate of successful classification by the logistic model. It is used to compare two model and the model with more coverage is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.\tExplain the steps for Heroku deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user login in Heroku\n",
    "Installing the Heroku CLI, Open a command prompt window and navigate to your project folder.\n",
    "Type the command heroku login to login to your heroku account.\n",
    "After logging in to Heroku, enter the command heroku create to create a heroku app. It will give you the URL of your Heroku app after successful creation. Or alternatively, you can go to the heroku website and create an app directly.\n",
    "Before deploying the code to the Heroku cloud, we need to commit the changes to the git repository.\n",
    "Type the command 'git init' to initialize a local git repository.\n",
    "Enter the command 'git add ' to add the uncommitted changes to the local repository.\n",
    "Enter the command 'git commit -am \"make it better\" ' to commit the changes to the local repository.\n",
    "Enter the command 'git push heroku master' to push the code to the heroku cloud.\n",
    "After deployment, go to heroku websit login and go to app->settings->get the URL to hit the web API.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.\tWhat difficulties did you face while deploying to Heroku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I creaded procfile with small letter 'P' got the error procfile not detected. Wheni check the procfile is there in the root folder. \n",
    "Then i findout the mistake and renamed the file still showed the same error procfile not detected. Then i deleted the app in heroku and recreated it and this time it worked fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
